{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4ee4d3f",
   "metadata": {},
   "source": [
    "### Описание задания:\n",
    "Применение рекуррентных нейросетей для решения проблем автоматической морфологической разметки(Part Of Speech Tagging)\n",
    "\n",
    "### Задачи:\n",
    "1) Создать RNN нейросеть\n",
    "2) Создать двунаправленную RNN нейросеть\n",
    "3) Создать RNN нейросеть с использованием CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5be3162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "203fa3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import sys\n",
    "import wget\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32d2585e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb8cdd6",
   "metadata": {},
   "source": [
    "### Получение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfa4a05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('brown', quiet=True)\n",
    "nltk.download('universal_tagset', quiet=True)\n",
    "data = nltk.corpus.brown.tagged_sents(tagset='universal')\n",
    "all_tags = ['#EOS#','#UNK#','ADV', 'NOUN', 'ADP', 'PRON', 'DET', '.', 'PRT', 'VERB', 'X', 'NUM', 'CONJ', 'ADJ']\n",
    "\n",
    "data = np.array([ [(word.lower(),tag) for word,tag in sentence] for sentence in data ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cba902c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57340,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3f7aaa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([('the', 'DET'), ('fulton', 'NOUN'), ('county', 'NOUN'), ('grand', 'ADJ'), ('jury', 'NOUN'), ('said', 'VERB'), ('friday', 'NOUN'), ('an', 'DET'), ('investigation', 'NOUN'), ('of', 'ADP'), (\"atlanta's\", 'NOUN'), ('recent', 'ADJ'), ('primary', 'NOUN'), ('election', 'NOUN'), ('produced', 'VERB'), ('``', '.'), ('no', 'DET'), ('evidence', 'NOUN'), (\"''\", '.'), ('that', 'ADP'), ('any', 'DET'), ('irregularities', 'NOUN'), ('took', 'VERB'), ('place', 'NOUN'), ('.', '.')]),\n",
       "       list([('the', 'DET'), ('jury', 'NOUN'), ('further', 'ADV'), ('said', 'VERB'), ('in', 'ADP'), ('term-end', 'NOUN'), ('presentments', 'NOUN'), ('that', 'ADP'), ('the', 'DET'), ('city', 'NOUN'), ('executive', 'ADJ'), ('committee', 'NOUN'), (',', '.'), ('which', 'DET'), ('had', 'VERB'), ('over-all', 'ADJ'), ('charge', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('election', 'NOUN'), (',', '.'), ('``', '.'), ('deserves', 'VERB'), ('the', 'DET'), ('praise', 'NOUN'), ('and', 'CONJ'), ('thanks', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('city', 'NOUN'), ('of', 'ADP'), ('atlanta', 'NOUN'), (\"''\", '.'), ('for', 'ADP'), ('the', 'DET'), ('manner', 'NOUN'), ('in', 'ADP'), ('which', 'DET'), ('the', 'DET'), ('election', 'NOUN'), ('was', 'VERB'), ('conducted', 'VERB'), ('.', '.')])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:2][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57cbba8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>NOUN</td><td>ADP</td><td>NOUN</td><td>NOUN</td><td>NOUN</td><td>NOUN</td><td>VERB</td><td>ADV</td><td>VERB</td><td>ADP</td><td>DET</td><td>ADJ</td><td>NOUN</td><td>.</td></tr><td>implementation</td><td>of</td><td>georgia's</td><td>automobile</td><td>title</td><td>law</td><td>was</td><td>also</td><td>recommended</td><td>by</td><td>the</td><td>outgoing</td><td>jury</td><td>.</td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>PRON</td><td>VERB</td><td>ADP</td><td>DET</td><td>NOUN</td><td>.</td><td>VERB</td><td>NOUN</td><td>PRT</td><td>VERB</td><td>.</td><td>DET</td><td>NOUN</td><td>.</td></tr><td>it</td><td>urged</td><td>that</td><td>the</td><td>city</td><td>``</td><td>take</td><td>steps</td><td>to</td><td>remedy</td><td>''</td><td>this</td><td>problem</td><td>.</td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>NOUN</td><td>VERB</td></tr><td>merger</td><td>proposed</td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def draw(sentence):\n",
    "    words,tags = zip(*sentence)\n",
    "    display(HTML('<table><tr>{tags}</tr>{words}<tr></table>'.format(\n",
    "                words = '<td>{}</td>'.format('</td><td>'.join(words)),\n",
    "                tags = '<td>{}</td>'.format('</td><td>'.join(tags)))))\n",
    "    \n",
    "    \n",
    "draw(data[11])\n",
    "draw(data[10])\n",
    "draw(data[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "368ab206",
   "metadata": {},
   "source": [
    "### Создание словарей для words и tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9af6a5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage = 0.92876\n"
     ]
    }
   ],
   "source": [
    "word_counts = Counter()\n",
    "for sentence in data:\n",
    "    words,tags = zip(*sentence)\n",
    "    word_counts.update(words)\n",
    "\n",
    "all_words = ['#EOS#','#UNK#'] + list(list(zip(*word_counts.most_common(10000)))[0])\n",
    "\n",
    "print(\"Coverage = %.5f\" % (float(sum(word_counts[w] for w in all_words)) / sum(word_counts.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aec32705",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id = defaultdict(lambda: 1, { word: ind for ind, word in enumerate(all_words) })\n",
    "tag_to_id = { tag: ind for ind, tag in enumerate(all_tags)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ece1893",
   "metadata": {},
   "source": [
    "Преобразование words и tags в матрицу фиксированного размера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40f95e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_matrix(lines, token_to_id, max_len=None, pad=0, dtype='int32', time_major=False):\n",
    "    \"\"\"Converts a list of names into rnn-digestable matrix with paddings added after the end\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len,lines))\n",
    "    matrix = np.empty([len(lines), max_len],dtype)\n",
    "    matrix.fill(pad)\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        line_ix = list(map(token_to_id.__getitem__,lines[i]))[:max_len]\n",
    "        matrix[i,:len(line_ix)] = line_ix\n",
    "\n",
    "    return matrix.T if time_major else matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d75ddc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word ids:\n",
      "[[   2 3057    5    2 2238 1334 4238 2454    3    6   19   26 1070   69\n",
      "     8 2088    6    3    1    3  266   65  342    2    1    3    2  315\n",
      "     1    9   87  216 3322   69 1558    4    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]\n",
      " [  45   12    8  511 8419    6   60 3246   39    2    1    1    3    2\n",
      "   845    1    3    1    3   10 9910    2    1 3470    9   43    1    1\n",
      "     3    6    2 1046  385   73 4562    3    9    2    1    1 3250    3\n",
      "    12   10    2  861 5240   12    8 8936  121    1    4]\n",
      " [  33   64   26   12  445    7 7346    9    8 3337    3    1 2811    3\n",
      "     2  463  572    2    1    1 1649   12    1    4    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n",
      "Tag ids:\n",
      "[[ 6  3  4  6  3  3  9  9  7 12  4  5  9  4  6  3 12  7  9  7  9  8  4  6\n",
      "   3  7  6 13  3  4  6  3  9  4  3  7  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 5  9  6  9  3 12  6  3  7  6 13  3  7  6 13  3  7 13  7  5  9  6  3  3\n",
      "   4  6 13  3  7 12  6  3  6 13  3  7  4  6  3  9  3  7  9  4  6 13  3  9\n",
      "   6  3  2 13  7]\n",
      " [ 4  6  5  9 13  4  3  4  6 13  7 13  3  7  6  3  4  6 13  3  3  9  9  7\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "batch_words, batch_tags = zip(*[zip(*sentence) for sentence in data[-3:]])\n",
    "\n",
    "print(\"Word ids:\")\n",
    "print(to_matrix(batch_words, word_to_id))\n",
    "print(\"Tag ids:\")\n",
    "print(to_matrix(batch_tags, tag_to_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f173dfa8",
   "metadata": {},
   "source": [
    "### Создание RNN нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8af239d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.25, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05e969dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size =  43005\n",
      "Test size =  14335\n"
     ]
    }
   ],
   "source": [
    "print(\"Train size = \", len(train_data))\n",
    "print(\"Test size = \", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d7061046",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(layers.InputLayer([None], dtype='int32'))\n",
    "model.add(layers.Embedding(len(all_words), 50))\n",
    "model.add(layers.SimpleRNN(64, return_sequences=True))\n",
    "\n",
    "#add top layer that predicts tag probabilities\n",
    "stepwise_dense = layers.Dense(len(all_tags), activation='softmax')\n",
    "stepwise_dense = layers.TimeDistributed(stepwise_dense)\n",
    "model.add(stepwise_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a527e7c9",
   "metadata": {},
   "source": [
    "Создание генератора, который возвращает по одному batch за раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fafcf660",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "def generate_batches(sentences, batch_size=BATCH_SIZE, max_len=None, pad=0):\n",
    "    assert isinstance(sentences, np.ndarray),\"Make sure sentences is q numpy array\"\n",
    "    \n",
    "    while True:\n",
    "        indices = np.random.permutation(np.arange(len(sentences)))\n",
    "        for start in range(0, len(indices) - 1, batch_size):\n",
    "            batch_indices = indices[start:start + batch_size]\n",
    "            batch_words, batch_tags = [], []\n",
    "            for sent in sentences[batch_indices]:\n",
    "                words,tags = zip(*sent)\n",
    "                batch_words.append(words)\n",
    "                batch_tags.append(tags)\n",
    "\n",
    "            batch_words = to_matrix(batch_words, word_to_id, max_len,pad)\n",
    "            batch_tags = to_matrix(batch_tags, tag_to_id, max_len,pad)\n",
    "\n",
    "            batch_tags_1hot = to_categorical(batch_tags, len(all_tags)).reshape(batch_tags.shape + (-1,))\n",
    "            yield batch_words, batch_tags_1hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5252bcb6",
   "metadata": {},
   "source": [
    "Создание метода для получения validation accuracy: целевой метрики модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bfe0651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_test_accuracy(model):\n",
    "    test_words, test_tags = zip(*[zip(*sentence) for sentence in test_data])\n",
    "    test_words, test_tags = to_matrix(test_words, word_to_id),to_matrix(test_tags, tag_to_id)\n",
    "\n",
    "    #predict tag probabilities of shape [batch,time,n_tags]\n",
    "    predicted_tag_probabilities = model.predict(test_words, verbose=1)\n",
    "    predicted_tags = predicted_tag_probabilities.argmax(axis=-1)\n",
    "\n",
    "    #compute accurary excluding padding\n",
    "    numerator = np.sum(np.logical_and((predicted_tags == test_tags), (test_words != 0)))\n",
    "    denominator = np.sum(test_words != 0)\n",
    "    return float(numerator) / denominator\n",
    "\n",
    "\n",
    "class EvaluateAccuracy(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self,epoch, logs=None):\n",
    "        sys.stdout.flush()\n",
    "        print(\"\\nMeasuring validation accuracy...\")\n",
    "        acc = compute_test_accuracy(self.model)\n",
    "        print(\"\\nValidation accuracy: %.5f\\n\"%acc)\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "86f3439d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.2407\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 40s 87ms/step\n",
      "\n",
      "Validation accuracy: 0.93994\n",
      "\n",
      "1343/1343 [==============================] - 174s 126ms/step - loss: 0.2407\n",
      "Epoch 2/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0582\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 37s 83ms/step\n",
      "\n",
      "Validation accuracy: 0.94380\n",
      "\n",
      "1343/1343 [==============================] - 180s 134ms/step - loss: 0.0582\n",
      "Epoch 3/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0514\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 34s 77ms/step\n",
      "\n",
      "Validation accuracy: 0.94493\n",
      "\n",
      "1343/1343 [==============================] - 178s 132ms/step - loss: 0.0514\n",
      "Epoch 4/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0470\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 33s 75ms/step\n",
      "\n",
      "Validation accuracy: 0.94564\n",
      "\n",
      "1343/1343 [==============================] - 187s 139ms/step - loss: 0.0470\n",
      "Epoch 5/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0432\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 36s 80ms/step\n",
      "\n",
      "Validation accuracy: 0.94455\n",
      "\n",
      "1343/1343 [==============================] - 184s 137ms/step - loss: 0.0432\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c09eea3250>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile('adam','categorical_crossentropy')\n",
    "\n",
    "model.fit_generator(generate_batches(train_data), len(train_data) / BATCH_SIZE, callbacks=[EvaluateAccuracy()], epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38a97ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 39s 88ms/step\n",
      "Final accuracy: 0.94455\n"
     ]
    }
   ],
   "source": [
    "acc = compute_test_accuracy(model)\n",
    "print(\"Final accuracy: %.5f\"%acc)\n",
    "\n",
    "assert acc > 0.94, \"Keras has gone on a rampage again, please contact course staff.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c798504",
   "metadata": {},
   "source": [
    "### Создание двунаправленной RNN нейросети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4194aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "bidirect_model = keras.models.Sequential()\n",
    "bidirect_model.add(layers.InputLayer([None], dtype='int32'))\n",
    "bidirect_model.add(layers.Embedding(len(all_words), 50))\n",
    "bidirect_model.add(layers.Bidirectional(layers.SimpleRNN(64, return_sequences=True)))\n",
    "bidirect_model.add(layers.Bidirectional(layers.LSTM(24, return_sequences=True)))\n",
    "\n",
    "stepwise_dense = layers.Dense(len(all_tags), activation='softmax')\n",
    "stepwise_dense = layers.TimeDistributed(stepwise_dense)\n",
    "bidirect_model.add(stepwise_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74d33cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.2379\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 131s 284ms/step\n",
      "\n",
      "Validation accuracy: 0.95621\n",
      "\n",
      "1343/1343 [==============================] - 632s 456ms/step - loss: 0.2379\n",
      "Epoch 2/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0429\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 131s 293ms/step\n",
      "\n",
      "Validation accuracy: 0.96193\n",
      "\n",
      "1343/1343 [==============================] - 608s 452ms/step - loss: 0.0429\n",
      "Epoch 3/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0340\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 135s 301ms/step\n",
      "\n",
      "Validation accuracy: 0.96303\n",
      "\n",
      "1343/1343 [==============================] - 703s 523ms/step - loss: 0.0340\n",
      "Epoch 4/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0282\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 28s 63ms/step\n",
      "\n",
      "Validation accuracy: 0.96370\n",
      "\n",
      "1343/1343 [==============================] - 497s 370ms/step - loss: 0.0282\n",
      "Epoch 5/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0233\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 28s 62ms/step\n",
      "\n",
      "Validation accuracy: 0.96257\n",
      "\n",
      "1343/1343 [==============================] - 170s 126ms/step - loss: 0.0233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c0ad9d5e70>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bidirect_model.compile('adam', 'categorical_crossentropy')\n",
    "\n",
    "bidirect_model.fit_generator(generate_batches(train_data),len(train_data) / BATCH_SIZE,\n",
    "                    callbacks=[EvaluateAccuracy()], epochs=5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "737face5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 28s 62ms/step\n",
      "\n",
      "Final accuracy: 0.96257\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "acc = compute_test_accuracy(bidirect_model)\n",
    "print(\"\\nFinal accuracy: %.5f\"%acc)\n",
    "\n",
    "assert acc > 0.96, \"Bidirectional RNNs are better than this!\"\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2a00f4",
   "metadata": {},
   "source": [
    "### Создание двунаправленной RNN нейросети c использованием Conditional Random Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b11bad2",
   "metadata": {},
   "source": [
    "**Примечание:** CRF входит в библиотку keras_contrib. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fcf7c8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://www.github.com/keras-team/keras-contrib.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ae662f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_contrib.layers import CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5129654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_model = keras.models.Sequential()\n",
    "crf_model.add(layers.InputLayer([None], dtype='int32'))\n",
    "crf_model.add(layers.Embedding(len(all_words), 50))\n",
    "crf_model.add(layers.Bidirectional(layers.SimpleRNN(64, return_sequences=True)))\n",
    "crf_model.add(layers.Bidirectional(layers.LSTM(24, return_sequences=True, recurrent_dropout=0.2)))\n",
    "\n",
    "stepwise_dense = CRF(len(all_tags), sparse_target=True)\n",
    "stepwise_dense = layers.Dense(len(all_tags), activation='softmax')\n",
    "stepwise_dense = layers.TimeDistributed(stepwise_dense)\n",
    "crf_model.add(stepwise_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "520a8be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.2649\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 49s 107ms/step\n",
      "\n",
      "Validation accuracy: 0.95677\n",
      "\n",
      "1343/1343 [==============================] - 312s 224ms/step - loss: 0.2649\n",
      "Epoch 2/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0447\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 47s 105ms/step\n",
      "\n",
      "Validation accuracy: 0.96080\n",
      "\n",
      "1343/1343 [==============================] - 293s 218ms/step - loss: 0.0447\n",
      "Epoch 3/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0363\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 48s 107ms/step\n",
      "\n",
      "Validation accuracy: 0.96337\n",
      "\n",
      "1343/1343 [==============================] - 304s 226ms/step - loss: 0.0363\n",
      "Epoch 4/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0305\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 52s 116ms/step\n",
      "\n",
      "Validation accuracy: 0.96356\n",
      "\n",
      "1343/1343 [==============================] - 335s 249ms/step - loss: 0.0305\n",
      "Epoch 5/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0267\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 46s 102ms/step\n",
      "\n",
      "Validation accuracy: 0.96312\n",
      "\n",
      "1343/1343 [==============================] - 284s 211ms/step - loss: 0.0267\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c0bc180160>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf_model.compile('adam', 'categorical_crossentropy')\n",
    "\n",
    "crf_model.fit_generator(generate_batches(train_data), len(train_data) / BATCH_SIZE,\n",
    "                        callbacks=[EvaluateAccuracy()], epochs=5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8dee4219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 46s 102ms/step\n",
      "\n",
      "CRF accuracy: 0.96312\n"
     ]
    }
   ],
   "source": [
    "acc = compute_test_accuracy(crf_model)\n",
    "print(\"\\nCRF accuracy: %.5f\"%acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df83ce5",
   "metadata": {},
   "source": [
    "**Вывод:** применение CRF не дало существенного преимущества по сравнению с обычной двунаправленной RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a0d137",
   "metadata": {},
   "source": [
    "### Использование предобученных words GloVe embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f76e585",
   "metadata": {},
   "source": [
    "**Внимание:** Размер предобученного GloVe embeddings - 822M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6147b1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip --no-check-certificate -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0c142812",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('glove.6B.zip', 'r') as zip_data:\n",
    "    zip_data.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "eafc4ba2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "path_to_glove_file = 'glove.6B.100d.txt'\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b4d8194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 40481 words (9336 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(all_words) + 2\n",
    "embedding_dim = 100\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_to_id.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f767ed14",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_model = keras.models.Sequential()\n",
    "glove_model.add(layers.InputLayer([None], dtype='int32'))\n",
    "glove_model.add(layers.Embedding(num_tokens,\n",
    "                                 embedding_dim,\n",
    "                                 embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "                                 trainable=False,))\n",
    "glove_model.add(layers.Bidirectional(layers.SimpleRNN(64, return_sequences=True)))\n",
    "glove_model.add(layers.Bidirectional(layers.LSTM(24, return_sequences=True, recurrent_dropout=0.1)))\n",
    "\n",
    "glove_stepwise_dense = CRF(len(all_tags), sparse_target=True)\n",
    "glove_stepwise_dense = layers.Dense(len(all_tags), activation='softmax')\n",
    "glove_stepwise_dense = layers.TimeDistributed(glove_stepwise_dense)\n",
    "glove_model.add(glove_stepwise_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8d1e9188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.1947\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 61s 125ms/step\n",
      "\n",
      "Validation accuracy: 0.93211\n",
      "\n",
      "1343/1343 [==============================] - 324s 232ms/step - loss: 0.1947\n",
      "Epoch 2/7\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0688\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 64s 143ms/step\n",
      "\n",
      "Validation accuracy: 0.94763\n",
      "\n",
      "1343/1343 [==============================] - 412s 307ms/step - loss: 0.0688\n",
      "Epoch 3/7\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0555\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 60s 134ms/step\n",
      "\n",
      "Validation accuracy: 0.95370\n",
      "\n",
      "1343/1343 [==============================] - 354s 264ms/step - loss: 0.0555\n",
      "Epoch 4/7\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0487\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 62s 138ms/step\n",
      "\n",
      "Validation accuracy: 0.95635\n",
      "\n",
      "1343/1343 [==============================] - 390s 290ms/step - loss: 0.0487\n",
      "Epoch 5/7\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0453\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 64s 142ms/step\n",
      "\n",
      "Validation accuracy: 0.95787\n",
      "\n",
      "1343/1343 [==============================] - 348s 259ms/step - loss: 0.0453\n",
      "Epoch 6/7\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0424\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 56s 125ms/step\n",
      "\n",
      "Validation accuracy: 0.95943\n",
      "\n",
      "1343/1343 [==============================] - 333s 248ms/step - loss: 0.0424\n",
      "Epoch 7/7\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0403\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 59s 131ms/step\n",
      "\n",
      "Validation accuracy: 0.96101\n",
      "\n",
      "1343/1343 [==============================] - 337s 251ms/step - loss: 0.0403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c10caec070>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_model.compile('adam', 'categorical_crossentropy')\n",
    "\n",
    "glove_model.fit_generator(generate_batches(train_data), len(train_data) / BATCH_SIZE,\n",
    "                    callbacks=[EvaluateAccuracy()], epochs=7,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cecd7319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 58s 129ms/step\n",
      "\n",
      "RNN with GloVe accuracy: 0.96101\n"
     ]
    }
   ],
   "source": [
    "acc = compute_test_accuracy(glove_model)\n",
    "print(\"\\nRNN with GloVe accuracy: %.5f\"%acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d89923d",
   "metadata": {},
   "source": [
    "**Вывод:** применение предобученных words GloVe embeddings не дало преимуществ в рамках соопставимого количества epoch по сравнению с обычной двунаправленной RNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52de30eb",
   "metadata": {},
   "source": [
    "### Выводы:\n",
    "\n",
    "В рамках проекта были реализованы различные схемы рекуррентных нейросетей:\n",
    "- однонаправленная RNN нейросеть\n",
    "- двунаправленная RNN нейросеть\n",
    "- двунаправленная RNN нейросеть c использованием Conditional Random Fields\n",
    "\n",
    "Также для нейросети был применён предобученный words GloVe embeddings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
