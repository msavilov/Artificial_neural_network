{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4ee4d3f",
   "metadata": {},
   "source": [
    "### Описание задания:\n",
    "Применение рекуррентных нейросетей для решения проблем автоматической морфологической разметки(Part Of Speech Tagging)\n",
    "\n",
    "### Задачи:\n",
    "1) Создать RNN нейросеть\n",
    "2) Создать двунаправленную RNN нейросеть\n",
    "3) Создать RNN нейросеть с использованием CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03c03df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53f86126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import os\n",
    "import sys\n",
    "import wget\n",
    "import zipfile\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69d0b6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.version.VERSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0e428d",
   "metadata": {},
   "source": [
    "### Получение данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46b3316c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\CaBa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\CaBa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('brown')\n",
    "nltk.download('universal_tagset')\n",
    "data = nltk.corpus.brown.tagged_sents(tagset='universal')\n",
    "all_tags = ['#EOS#','#UNK#','ADV', 'NOUN', 'ADP', 'PRON', 'DET', '.', 'PRT', 'VERB', 'X', 'NUM', 'CONJ', 'ADJ']\n",
    "\n",
    "data = np.array([ [(word.lower(),tag) for word,tag in sentence] for sentence in data ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4011f561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57340,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb2fd341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([('the', 'DET'), ('fulton', 'NOUN'), ('county', 'NOUN'), ('grand', 'ADJ'), ('jury', 'NOUN'), ('said', 'VERB'), ('friday', 'NOUN'), ('an', 'DET'), ('investigation', 'NOUN'), ('of', 'ADP'), (\"atlanta's\", 'NOUN'), ('recent', 'ADJ'), ('primary', 'NOUN'), ('election', 'NOUN'), ('produced', 'VERB'), ('``', '.'), ('no', 'DET'), ('evidence', 'NOUN'), (\"''\", '.'), ('that', 'ADP'), ('any', 'DET'), ('irregularities', 'NOUN'), ('took', 'VERB'), ('place', 'NOUN'), ('.', '.')]),\n",
       "       list([('the', 'DET'), ('jury', 'NOUN'), ('further', 'ADV'), ('said', 'VERB'), ('in', 'ADP'), ('term-end', 'NOUN'), ('presentments', 'NOUN'), ('that', 'ADP'), ('the', 'DET'), ('city', 'NOUN'), ('executive', 'ADJ'), ('committee', 'NOUN'), (',', '.'), ('which', 'DET'), ('had', 'VERB'), ('over-all', 'ADJ'), ('charge', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('election', 'NOUN'), (',', '.'), ('``', '.'), ('deserves', 'VERB'), ('the', 'DET'), ('praise', 'NOUN'), ('and', 'CONJ'), ('thanks', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('city', 'NOUN'), ('of', 'ADP'), ('atlanta', 'NOUN'), (\"''\", '.'), ('for', 'ADP'), ('the', 'DET'), ('manner', 'NOUN'), ('in', 'ADP'), ('which', 'DET'), ('the', 'DET'), ('election', 'NOUN'), ('was', 'VERB'), ('conducted', 'VERB'), ('.', '.')])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:2][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a12e3d19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td>NOUN</td><td>ADP</td><td>NOUN</td><td>NOUN</td><td>NOUN</td><td>NOUN</td><td>VERB</td><td>ADV</td><td>VERB</td><td>ADP</td><td>DET</td><td>ADJ</td><td>NOUN</td><td>.</td></tr><td>implementation</td><td>of</td><td>georgia's</td><td>automobile</td><td>title</td><td>law</td><td>was</td><td>also</td><td>recommended</td><td>by</td><td>the</td><td>outgoing</td><td>jury</td><td>.</td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>PRON</td><td>VERB</td><td>ADP</td><td>DET</td><td>NOUN</td><td>.</td><td>VERB</td><td>NOUN</td><td>PRT</td><td>VERB</td><td>.</td><td>DET</td><td>NOUN</td><td>.</td></tr><td>it</td><td>urged</td><td>that</td><td>the</td><td>city</td><td>``</td><td>take</td><td>steps</td><td>to</td><td>remedy</td><td>''</td><td>this</td><td>problem</td><td>.</td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr><td>NOUN</td><td>VERB</td></tr><td>merger</td><td>proposed</td><tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def draw(sentence):\n",
    "    words,tags = zip(*sentence)\n",
    "    display(HTML('<table><tr>{tags}</tr>{words}<tr></table>'.format(\n",
    "                words = '<td>{}</td>'.format('</td><td>'.join(words)),\n",
    "                tags = '<td>{}</td>'.format('</td><td>'.join(tags)))))\n",
    "    \n",
    "    \n",
    "draw(data[11])\n",
    "draw(data[10])\n",
    "draw(data[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48023336",
   "metadata": {},
   "source": [
    "### Создание словарей для words и tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8726d0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coverage = 0.92876\n"
     ]
    }
   ],
   "source": [
    "word_counts = Counter()\n",
    "for sentence in data:\n",
    "    words,tags = zip(*sentence)\n",
    "    word_counts.update(words)\n",
    "\n",
    "all_words = ['#EOS#','#UNK#'] + list(list(zip(*word_counts.most_common(10000)))[0])\n",
    "\n",
    "print(\"Coverage = %.5f\" % (float(sum(word_counts[w] for w in all_words)) / sum(word_counts.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c1c2e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_id = defaultdict(lambda: 1, { word: ind for ind, word in enumerate(all_words) })\n",
    "tag_to_id = { tag: ind for ind, tag in enumerate(all_tags)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4033f0a",
   "metadata": {},
   "source": [
    "Преобразование words и tags в матрицу фиксированного размера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abceaee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_matrix(lines, token_to_id, max_len=None, pad=0, dtype='int32', time_major=False):\n",
    "    \"\"\"Converts a list of names into rnn-digestable matrix with paddings added after the end\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len,lines))\n",
    "    matrix = np.empty([len(lines), max_len],dtype)\n",
    "    matrix.fill(pad)\n",
    "\n",
    "    for i in range(len(lines)):\n",
    "        line_ix = list(map(token_to_id.__getitem__,lines[i]))[:max_len]\n",
    "        matrix[i,:len(line_ix)] = line_ix\n",
    "\n",
    "    return matrix.T if time_major else matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2cc5947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word ids:\n",
      "[[   2 3057    5    2 2238 1334 4238 2454    3    6   19   26 1070   69\n",
      "     8 2088    6    3    1    3  266   65  342    2    1    3    2  315\n",
      "     1    9   87  216 3322   69 1558    4    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]\n",
      " [  45   12    8  511 8419    6   60 3246   39    2    1    1    3    2\n",
      "   845    1    3    1    3   10 9910    2    1 3470    9   43    1    1\n",
      "     3    6    2 1046  385   73 4562    3    9    2    1    1 3250    3\n",
      "    12   10    2  861 5240   12    8 8936  121    1    4]\n",
      " [  33   64   26   12  445    7 7346    9    8 3337    3    1 2811    3\n",
      "     2  463  572    2    1    1 1649   12    1    4    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0]]\n",
      "Tag ids:\n",
      "[[ 6  3  4  6  3  3  9  9  7 12  4  5  9  4  6  3 12  7  9  7  9  8  4  6\n",
      "   3  7  6 13  3  4  6  3  9  4  3  7  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]\n",
      " [ 5  9  6  9  3 12  6  3  7  6 13  3  7  6 13  3  7 13  7  5  9  6  3  3\n",
      "   4  6 13  3  7 12  6  3  6 13  3  7  4  6  3  9  3  7  9  4  6 13  3  9\n",
      "   6  3  2 13  7]\n",
      " [ 4  6  5  9 13  4  3  4  6 13  7 13  3  7  6  3  4  6 13  3  3  9  9  7\n",
      "   0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "batch_words, batch_tags = zip(*[zip(*sentence) for sentence in data[-3:]])\n",
    "\n",
    "print(\"Word ids:\")\n",
    "print(to_matrix(batch_words, word_to_id))\n",
    "print(\"Tag ids:\")\n",
    "print(to_matrix(batch_tags, tag_to_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57361a0b",
   "metadata": {},
   "source": [
    "### Создание RNN нейросети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a5ebffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.25, random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0fdb6873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size =  43005\n",
      "Test size =  14335\n"
     ]
    }
   ],
   "source": [
    "print(\"Train size = \", len(train_data))\n",
    "print(\"Test size = \", len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cac17a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(layers.InputLayer([None], dtype='int32'))\n",
    "model.add(layers.Embedding(len(all_words), 50))\n",
    "model.add(layers.SimpleRNN(64, return_sequences=True))\n",
    "\n",
    "#add top layer that predicts tag probabilities\n",
    "stepwise_dense = layers.Dense(len(all_tags), activation='softmax')\n",
    "stepwise_dense = layers.TimeDistributed(stepwise_dense)\n",
    "model.add(stepwise_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fdebda",
   "metadata": {},
   "source": [
    "Создание генератора, который возвращает по одному batch за раз"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a81e6858",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "def generate_batches(sentences, batch_size=BATCH_SIZE, max_len=None, pad=0):\n",
    "    assert isinstance(sentences, np.ndarray),\"Make sure sentences is q numpy array\"\n",
    "    \n",
    "    while True:\n",
    "        indices = np.random.permutation(np.arange(len(sentences)))\n",
    "        for start in range(0, len(indices) - 1, batch_size):\n",
    "            batch_indices = indices[start:start + batch_size]\n",
    "            batch_words, batch_tags = [], []\n",
    "            for sent in sentences[batch_indices]:\n",
    "                words,tags = zip(*sent)\n",
    "                batch_words.append(words)\n",
    "                batch_tags.append(tags)\n",
    "\n",
    "            batch_words = to_matrix(batch_words, word_to_id, max_len,pad)\n",
    "            batch_tags = to_matrix(batch_tags, tag_to_id, max_len,pad)\n",
    "\n",
    "            batch_tags_1hot = to_categorical(batch_tags, len(all_tags)).reshape(batch_tags.shape + (-1,))\n",
    "            yield batch_words, batch_tags_1hot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a695f9c9",
   "metadata": {},
   "source": [
    "Создание метода для измерение производительности модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc00a0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_test_accuracy(model):\n",
    "    test_words, test_tags = zip(*[zip(*sentence) for sentence in test_data])\n",
    "    test_words, test_tags = to_matrix(test_words, word_to_id),to_matrix(test_tags, tag_to_id)\n",
    "\n",
    "    #predict tag probabilities of shape [batch,time,n_tags]\n",
    "    predicted_tag_probabilities = model.predict(test_words, verbose=1)\n",
    "    predicted_tags = predicted_tag_probabilities.argmax(axis=-1)\n",
    "\n",
    "    #compute accurary excluding padding\n",
    "    numerator = np.sum(np.logical_and((predicted_tags == test_tags), (test_words != 0)))\n",
    "    denominator = np.sum(test_words != 0)\n",
    "    return float(numerator) / denominator\n",
    "\n",
    "\n",
    "class EvaluateAccuracy(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self,epoch, logs=None):\n",
    "        sys.stdout.flush()\n",
    "        print(\"\\nMeasuring validation accuracy...\")\n",
    "        acc = compute_test_accuracy(self.model)\n",
    "        print(\"\\nValidation accuracy: %.5f\\n\"%acc)\n",
    "        sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1d18c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.2404\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 11s 23ms/step\n",
      "\n",
      "Validation accuracy: 0.93987\n",
      "\n",
      "1343/1343 [==============================] - 73s 52ms/step - loss: 0.2404\n",
      "Epoch 2/5\n",
      "1343/1343 [============================>.] - ETA: 0s - loss: 0.0579\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 15s 34ms/step\n",
      "\n",
      "Validation accuracy: 0.94431\n",
      "\n",
      "1343/1343 [==============================] - 76s 56ms/step - loss: 0.0579\n",
      "Epoch 3/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0512\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 11s 25ms/step\n",
      "\n",
      "Validation accuracy: 0.94670\n",
      "\n",
      "1343/1343 [==============================] - 78s 58ms/step - loss: 0.0512\n",
      "Epoch 4/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0465\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 12s 26ms/step\n",
      "\n",
      "Validation accuracy: 0.94631\n",
      "\n",
      "1343/1343 [==============================] - 68s 51ms/step - loss: 0.0465\n",
      "Epoch 5/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0425\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 11s 24ms/step\n",
      "\n",
      "Validation accuracy: 0.94475\n",
      "\n",
      "1343/1343 [==============================] - 70s 52ms/step - loss: 0.0425\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fe4b2467a0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile('adam','categorical_crossentropy')\n",
    "\n",
    "model.fit_generator(generate_batches(train_data), len(train_data) / BATCH_SIZE, callbacks=[EvaluateAccuracy()], epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0dba4906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 11s 23ms/step\n",
      "Final accuracy: 0.94475\n"
     ]
    }
   ],
   "source": [
    "acc = compute_test_accuracy(model)\n",
    "print(\"Final accuracy: %.5f\"%acc)\n",
    "\n",
    "assert acc > 0.94, \"Keras has gone on a rampage again, please contact course staff.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6751f000",
   "metadata": {},
   "source": [
    "### Создание двунаправленной RNN нейросети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0075cf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "bidirect_model = keras.models.Sequential()\n",
    "bidirect_model.add(layers.InputLayer([None], dtype='int32'))\n",
    "bidirect_model.add(layers.Embedding(len(all_words), 50))\n",
    "bidirect_model.add(layers.Bidirectional(layers.SimpleRNN(64, return_sequences=True)))\n",
    "bidirect_model.add(layers.Bidirectional(layers.LSTM(24, return_sequences=True)))\n",
    "\n",
    "stepwise_dense = layers.Dense(len(all_tags), activation='softmax')\n",
    "stepwise_dense = layers.TimeDistributed(stepwise_dense)\n",
    "bidirect_model.add(stepwise_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f48a0917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.2473\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 56s 117ms/step\n",
      "\n",
      "Validation accuracy: 0.95681\n",
      "\n",
      "1343/1343 [==============================] - 272s 194ms/step - loss: 0.2473\n",
      "Epoch 2/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0441\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 53s 117ms/step\n",
      "\n",
      "Validation accuracy: 0.96125\n",
      "\n",
      "1343/1343 [==============================] - 275s 204ms/step - loss: 0.0441\n",
      "Epoch 3/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0356\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 39s 88ms/step\n",
      "\n",
      "Validation accuracy: 0.96351\n",
      "\n",
      "1343/1343 [==============================] - 260s 194ms/step - loss: 0.0356\n",
      "Epoch 4/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0299\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 42s 94ms/step\n",
      "\n",
      "Validation accuracy: 0.96380\n",
      "\n",
      "1343/1343 [==============================] - 276s 205ms/step - loss: 0.0299\n",
      "Epoch 5/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0247\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 40s 89ms/step\n",
      "\n",
      "Validation accuracy: 0.96261\n",
      "\n",
      "1343/1343 [==============================] - 224s 167ms/step - loss: 0.0247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fe7d8e6380>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bidirect_model.compile('adam', 'categorical_crossentropy')\n",
    "\n",
    "bidirect_model.fit_generator(generate_batches(train_data),len(train_data) / BATCH_SIZE,\n",
    "                    callbacks=[EvaluateAccuracy()], epochs=5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5b11eee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 41s 91ms/step\n",
      "\n",
      "Final accuracy: 0.96261\n",
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "acc = compute_test_accuracy(bidirect_model)\n",
    "print(\"\\nFinal accuracy: %.5f\"%acc)\n",
    "\n",
    "assert acc > 0.96, \"Bidirectional RNNs are better than this!\"\n",
    "print(\"Well done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a057140",
   "metadata": {},
   "source": [
    "### Создание двунаправленной RNN нейросети c использованием Conditional Random Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d80c99",
   "metadata": {},
   "source": [
    "CRF входит в библиотку keras_contrib. Установка: !pip install git+https://www.github.com/keras-team/keras-contrib.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e2467a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_contrib.layers import CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0c98e929",
   "metadata": {},
   "outputs": [],
   "source": [
    "crf_model = keras.models.Sequential()\n",
    "crf_model.add(layers.InputLayer([None], dtype='int32'))\n",
    "crf_model.add(layers.Embedding(len(all_words), 50))\n",
    "crf_model.add(layers.Bidirectional(layers.SimpleRNN(64, return_sequences=True)))\n",
    "crf_model.add(layers.Bidirectional(layers.LSTM(24, return_sequences=True)))\n",
    "\n",
    "stepwise_dense = CRF(len(all_tags), sparse_target=True)\n",
    "stepwise_dense = layers.Dense(len(all_tags), activation='softmax')\n",
    "stepwise_dense = layers.TimeDistributed(stepwise_dense)\n",
    "crf_model.add(stepwise_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8806798d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.2543\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 39s 83ms/step\n",
      "\n",
      "Validation accuracy: 0.95495\n",
      "\n",
      "1343/1343 [==============================] - 267s 190ms/step - loss: 0.2543\n",
      "Epoch 2/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0458\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 42s 93ms/step\n",
      "\n",
      "Validation accuracy: 0.96133\n",
      "\n",
      "1343/1343 [==============================] - 242s 180ms/step - loss: 0.0458\n",
      "Epoch 3/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0360\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 39s 87ms/step\n",
      "\n",
      "Validation accuracy: 0.96257\n",
      "\n",
      "1343/1343 [==============================] - 251s 187ms/step - loss: 0.0360\n",
      "Epoch 4/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0300\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 44s 99ms/step\n",
      "\n",
      "Validation accuracy: 0.96340\n",
      "\n",
      "1343/1343 [==============================] - 238s 177ms/step - loss: 0.0300\n",
      "Epoch 5/5\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0247\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 35s 78ms/step\n",
      "\n",
      "Validation accuracy: 0.96194\n",
      "\n",
      "1343/1343 [==============================] - 232s 173ms/step - loss: 0.0247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1fe7ff49300>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf_model.compile('adam', 'categorical_crossentropy')\n",
    "\n",
    "crf_model.fit_generator(generate_batches(train_data), len(train_data) / BATCH_SIZE,\n",
    "                    callbacks=[EvaluateAccuracy()], epochs=5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5317c74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 37s 83ms/step\n",
      "\n",
      "CRF accuracy: 0.96194\n"
     ]
    }
   ],
   "source": [
    "acc = compute_test_accuracy(crf_model)\n",
    "print(\"\\nCRF accuracy: %.5f\"%acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf30dc01",
   "metadata": {},
   "source": [
    "### Использование предобученных GloVe embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6664a076",
   "metadata": {},
   "source": [
    "**Внимание:** Размер предобученного GloVe embeddings - 822M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faac760",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget http://nlp.stanford.edu/data/glove.6B.zip --no-check-certificate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6407087",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile('glove.6B.zip', 'r') as zip_data:\n",
    "    zip_data.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f0fc788f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "path_to_glove_file = 'glove.6B.100d.txt'\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(path_to_glove_file, encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0f8c403d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 40481 words (9336 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(all_words) + 2\n",
    "embedding_dim = 100\n",
    "hits = 0\n",
    "misses = 0\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_to_id.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bc2b587e",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_model = keras.models.Sequential()\n",
    "glove_model.add(layers.InputLayer([None], dtype='int32'))\n",
    "glove_model.add(layers.Embedding(num_tokens,\n",
    "                                 embedding_dim,\n",
    "                                 embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "                                 trainable=False,))\n",
    "glove_model.add(layers.Bidirectional(layers.SimpleRNN(64, return_sequences=True)))\n",
    "glove_model.add(layers.Bidirectional(layers.LSTM(24, return_sequences=True)))\n",
    "\n",
    "glove_stepwise_dense = CRF(len(all_tags), sparse_target=True)\n",
    "glove_stepwise_dense = layers.Dense(len(all_tags), activation='softmax')\n",
    "glove_stepwise_dense = layers.TimeDistributed(glove_stepwise_dense)\n",
    "glove_model.add(glove_stepwise_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7aead4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/7\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.1933\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 40s 82ms/step\n",
      "\n",
      "Validation accuracy: 0.93344\n",
      "\n",
      "1343/1343 [==============================] - 219s 154ms/step - loss: 0.1933\n",
      "Epoch 2/7\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0681\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 37s 83ms/step\n",
      "\n",
      "Validation accuracy: 0.94736\n",
      "\n",
      "1343/1343 [==============================] - 217s 162ms/step - loss: 0.0681\n",
      "Epoch 3/7\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0552\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 51s 115ms/step\n",
      "\n",
      "Validation accuracy: 0.95350\n",
      "\n",
      "1343/1343 [==============================] - 239s 178ms/step - loss: 0.0552\n",
      "Epoch 4/7\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0487\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 50s 110ms/step\n",
      "\n",
      "Validation accuracy: 0.95620\n",
      "\n",
      "1343/1343 [==============================] - 228s 170ms/step - loss: 0.0487\n",
      "Epoch 5/7\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0450\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 40s 90ms/step\n",
      "\n",
      "Validation accuracy: 0.95910\n",
      "\n",
      "1343/1343 [==============================] - 227s 169ms/step - loss: 0.0450\n",
      "Epoch 6/7\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0427\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 41s 91ms/step\n",
      "\n",
      "Validation accuracy: 0.96033\n",
      "\n",
      "1343/1343 [==============================] - 241s 179ms/step - loss: 0.0427\n",
      "Epoch 7/7\n",
      "1344/1343 [==============================] - ETA: 0s - loss: 0.0403\n",
      "Measuring validation accuracy...\n",
      "448/448 [==============================] - 39s 87ms/step\n",
      "\n",
      "Validation accuracy: 0.96150\n",
      "\n",
      "1343/1343 [==============================] - 217s 161ms/step - loss: 0.0403\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1feaae9d720>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_model.compile('adam', 'categorical_crossentropy')\n",
    "\n",
    "glove_model.fit_generator(generate_batches(train_data), len(train_data) / BATCH_SIZE,\n",
    "                    callbacks=[EvaluateAccuracy()], epochs=7,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e66ae70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 40s 88ms/step\n",
      "\n",
      "RNN with GloVe accuracy: 0.96150\n"
     ]
    }
   ],
   "source": [
    "acc = compute_test_accuracy(glove_model)\n",
    "print(\"\\nRNN with GloVe accuracy: %.5f\"%acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab28516a",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "\n",
    "В рамках проекта были реализованы различные схемы рекуррентных нейросетей:\n",
    "- однонаправленная RNN нейросеть\n",
    "- двунаправленная RNN нейросеть\n",
    "- двунаправленная RNN нейросеть c использованием Conditional Random Fields\n",
    "\n",
    "Также для нейросети был применён предобученный GloVe embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfab99f",
   "metadata": {},
   "source": [
    "### Для проверяющего\n",
    "\n",
    "Предполагалось, что применение доп. методов улучшит Validation accuracy. Но нейросети с применением CRF и предобученного GloVe embeddings показали такую же Validation accuracy как и обычная двунаправленная RNN нейросеть. \n",
    "\n",
    "Подскажите, с чем это связано, и как можно улучшить работу сети?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
